mun1<-(mu0/t20+n1*ybar1/phi[4])*t2n1
phi[2]<-rnorm(1,mun1,sqrt(t2n1))
nun1<-nu0+n1
s2n1<-1/nun1*(nu0*s20+(n1-1)*vary1+n1*(ybar1-phi[2])^2)
phi[4]<-1/rgamma(1,nun1/2,nun1*s2n1/2)
t2n2<-1/(1/t20+n2/phi[5])
mun2<-(mu0/t20+n2*ybar2/phi[5])*t2n2
phi[3]<-rnorm(1,mun2,sqrt(t2n2))
nun2<-nu0+n2
s2n2<-1/nun2*(nu0*s20+(n2-1)*vary2+n2*(ybar2-phi[3])^2)
phi[5]<-1/rgamma(1,nun2/2,nun2*s2n2/2)
PHI[s,]<-phi
Xm[s,]<-sample(c(1,2),n,prob=c(phi[1],1-phi[1]),replace=T)
}
PHI[200,]
PHI[2000,]
a<-1
b<-1
n<-length(glucose)
mu0<-120
t20<-200
s20<-1000
nu0<-10
library(coda)
S<-10000
theta1<-mean(glucose)
theta2<-mean(glucose)
s21<-var(glucose)
s22<-var(glucose)
p1<-rbeta(1,a,b)
x<-sample(c(1,2),n,prob=c(p1,1-p1),replace=T)
PHI<-matrix(nrow=S,ncol=5)
Xm<-matrix(nrow=S,ncol=n)
Xm[1,]<-x
PHI[1,]<-phi<-c(p1,theta1,theta2,s21,s22)
set.seed(234)
for(s in 2:4000) {
phi[1]<-rbeta(1,a+2*n-sum(Xm[s-1,]),b+sum(Xm[s-1,])-n)
index1<-which(Xm[s-1,]==1)
n1<-sum(Xm[s-1,]==1)
n2<-sum(Xm[s-1,]==2)
index2<-which(Xm[s-1,]==2)
ybar1<-mean(glucose[index1])
ybar2<-mean(glucose[index2])
vary1<-ifelse(n1<=1,0,var(glucose[index1]))
vary2<-ifelse(n2<=1,0,var(glucose[index2]))
t2n1<-1/(1/t20+n1/phi[4])
mun1<-(mu0/t20+n1*ybar1/phi[4])*t2n1
phi[2]<-rnorm(1,mun1,sqrt(t2n1))
nun1<-nu0+n1
s2n1<-1/nun1*(nu0*s20+(n1-1)*vary1+n1*(ybar1-phi[2])^2)
phi[4]<-1/rgamma(1,nun1/2,nun1*s2n1/2)
t2n2<-1/(1/t20+n2/phi[5])
mun2<-(mu0/t20+n2*ybar2/phi[5])*t2n2
phi[3]<-rnorm(1,mun2,sqrt(t2n2))
nun2<-nu0+n2
s2n2<-1/nun2*(nu0*s20+(n2-1)*vary2+n2*(ybar2-phi[3])^2)
phi[5]<-1/rgamma(1,nun2/2,nun2*s2n2/2)
PHI[s,]<-phi
Xm[s,]<-sample(c(1,2),n,prob=c(phi[1],1-phi[1]),replace=T)
}
PHI[3000,]
PHI[2500,]
PHI[2200,]
PHI[2000,]
PHI[2100,]
PHI[2000:2100,]
PHI[2036,]
PHI[2037,]
s=2037
phi<-PJI[2036,]
phi<-PHI[2036,]
phi[1]<-rbeta(1,a+2*n-sum(Xm[s-1,]),b+sum(Xm[s-1,])-n)
phi
index1<-which(Xm[s-1,]==1)
n1<-sum(Xm[s-1,]==1)
n2<-sum(Xm[s-1,]==2)
index2<-which(Xm[s-1,]==2)
ybar1<-mean(glucose[index1])
ybar2<-mean(glucose[index2])
vary1<-ifelse(n1<=1,0,var(glucose[index1]))
vary2<-ifelse(n2<=1,0,var(glucose[index2]))
t2n1<-1/(1/t20+n1/phi[4])
mun1<-(mu0/t20+n1*ybar1/phi[4])*t2n1
phi[2]<-rnorm(1,mun1,sqrt(t2n1))
mun1
t2n1
mu0/t20+n1*ybar1/phi[4]
n1
ybar1
a<-1
b<-1
n<-length(glucose)
mu0<-120
t20<-200
s20<-1000
nu0<-10
library(coda)
S<-10000
theta1<-mean(glucose)
theta2<-mean(glucose)
s21<-var(glucose)
s22<-var(glucose)
p1<-rbeta(1,a,b)
x<-sample(c(1,2),n,prob=c(p1,1-p1),replace=T)
PHI<-matrix(nrow=S,ncol=5)
Xm<-matrix(nrow=S,ncol=n)
Xm[1,]<-x
PHI[1,]<-phi<-c(p1,theta1,theta2,s21,s22)
set.seed(234)
for(s in 2:4000) {
phi[1]<-rbeta(1,a+2*n-sum(Xm[s-1,]),b+sum(Xm[s-1,])-n)
index1<-which(Xm[s-1,]==1)
n1<-sum(Xm[s-1,]==1)
n2<-sum(Xm[s-1,]==2)
index2<-which(Xm[s-1,]==2)
ybar1<-ifelse(n1==0,0,mean(glucose[index1]))
ybar2<-ifelse(n2==0,0,mean(glucose[index2]))
vary1<-ifelse(n1<=1,0,var(glucose[index1]))
vary2<-ifelse(n2<=1,0,var(glucose[index2]))
t2n1<-1/(1/t20+n1/phi[4])
mun1<-(mu0/t20+n1*ybar1/phi[4])*t2n1
phi[2]<-rnorm(1,mun1,sqrt(t2n1))
nun1<-nu0+n1
s2n1<-1/nun1*(nu0*s20+(n1-1)*vary1+n1*(ybar1-phi[2])^2)
phi[4]<-1/rgamma(1,nun1/2,nun1*s2n1/2)
t2n2<-1/(1/t20+n2/phi[5])
mun2<-(mu0/t20+n2*ybar2/phi[5])*t2n2
phi[3]<-rnorm(1,mun2,sqrt(t2n2))
nun2<-nu0+n2
s2n2<-1/nun2*(nu0*s20+(n2-1)*vary2+n2*(ybar2-phi[3])^2)
phi[5]<-1/rgamma(1,nun2/2,nun2*s2n2/2)
PHI[s,]<-phi
Xm[s,]<-sample(c(1,2),n,prob=c(phi[1],1-phi[1]),replace=T)
}
a<-1
b<-1
n<-length(glucose)
mu0<-120
t20<-200
s20<-1000
nu0<-10
library(coda)
S<-10000
theta1<-mean(glucose)
theta2<-mean(glucose)
s21<-var(glucose)
s22<-var(glucose)
p1<-rbeta(1,a,b)
x<-sample(c(1,2),n,prob=c(p1,1-p1),replace=T)
PHI<-matrix(nrow=S,ncol=5)
Xm<-matrix(nrow=S,ncol=n)
Xm[1,]<-x
PHI[1,]<-phi<-c(p1,theta1,theta2,s21,s22)
for(s in 2:S) {
phi[1]<-rbeta(1,a+2*n-sum(Xm[s-1,]),b+sum(Xm[s-1,])-n)
index1<-which(Xm[s-1,]==1)
n1<-sum(Xm[s-1,]==1)
n2<-sum(Xm[s-1,]==2)
index2<-which(Xm[s-1,]==2)
ybar1<-ifelse(n1==0,0,mean(glucose[index1]))
ybar2<-ifelse(n2==0,0,mean(glucose[index2]))
vary1<-ifelse(n1<=1,0,var(glucose[index1]))
vary2<-ifelse(n2<=1,0,var(glucose[index2]))
t2n1<-1/(1/t20+n1/phi[4])
mun1<-(mu0/t20+n1*ybar1/phi[4])*t2n1
phi[2]<-rnorm(1,mun1,sqrt(t2n1))
nun1<-nu0+n1
s2n1<-1/nun1*(nu0*s20+(n1-1)*vary1+n1*(ybar1-phi[2])^2)
phi[4]<-1/rgamma(1,nun1/2,nun1*s2n1/2)
t2n2<-1/(1/t20+n2/phi[5])
mun2<-(mu0/t20+n2*ybar2/phi[5])*t2n2
phi[3]<-rnorm(1,mun2,sqrt(t2n2))
nun2<-nu0+n2
s2n2<-1/nun2*(nu0*s20+(n2-1)*vary2+n2*(ybar2-phi[3])^2)
phi[5]<-1/rgamma(1,nun2/2,nun2*s2n2/2)
PHI[s,]<-phi
Xm[s,]<-sample(c(1,2),n,prob=c(phi[1],1-phi[1]),replace=T)
}
PHI[S,]
apply(PHI[,c(2,3)],max,2)
apply(PHI[,c(2,3)],2,max)
apply(PHI[,c(2,3)],1,max)
thetamax<-apply(PHI[,c(2,3)],1,max)
thetamin<-apply(PHI[,c(2,3)],1,min)
acf(thetamax)
acf(thetamax)
effectivesize(thetamax)
effectiveSize(thetamax)
acf(thetamax)
acf(thetamin)
acf(thetamax)
acf(thetamin)
#autocorrelation for theta(1)
acf(thetamin)
#autocorrelation for theta(2)
acf(thetamax)
#effective sample sizes of theta(1)
effectiveSize(thetamin)
#effectice sample sizes of theta(2)
effectiveSize(thetamax)
PHI[i,1]
x<-c()
for(i in 1:S){
x[i]<-sample(c(1,2),1,prob=c(PHI[i,1],1-PHI[i,1]))
}
x
x<-c()
Y<-c()
for(i in 1:S){
x[i]<-sample(c(1,2),1,prob=c(PHI[i,1],1-PHI[i,1]))
if(x[i]==1){
Y[i]<-rnorm(1,PHI[i,2],sqrt(PHI[i,4]))
}else{
Y[i]<-rnorm(1,PHI[i,3],sqrt(PHI[i,5]))
}
}
plot(Y)
hist(Y)
hist(Y,breaks=50)
men_bach<-as.numeric(as.matrix(read.csv("men30bach.txt",header=F,sep=" ")))
men_bach<-as.numeric(na.omit(men_bach))
men_nobach<-as.numeric(as.matrix(read.csv("men30nobach.txt",header=F,sep=" ")))
men_nobach<-as.numeric(na.omit(men_nobach))
#theta Gamma(2,1)
a<-2
b<-1
#bach
n_bach<-length(men_bach)
y_bach<-sum(men_bach)
#nobach
n_nobach<-length(men_nobach)
y_nobach<-sum(men_nobach)
y_bach+y_nobach
n_bach+n_nobach
n_bach
n_nobach
y_nobach
y_bach
?rbinom
a<-1
b<-1
n<-length(glucose)
mu0<-120
t20<-200
s20<-1000
nu0<-10
library(coda)
S<-10000
theta1<-mean(glucose)
theta2<-mean(glucose)
s21<-var(glucose)
s22<-var(glucose)
p1<-rbeta(1,a,b)
x<-sample(c(1,2),n,prob=c(p1,1-p1),replace=T)
PHI<-matrix(nrow=S,ncol=5)
Xm<-matrix(nrow=S,ncol=n)
Xm[1,]<-x
PHI[1,]<-phi<-c(p1,theta1,theta2,s21,s22)
for(s in 2:S) {
phi[1]<-rbeta(1,a+2*n-sum(Xm[s-1,]),b+sum(Xm[s-1,])-n)
index1<-which(Xm[s-1,]==1)
n1<-sum(Xm[s-1,]==1)
n2<-sum(Xm[s-1,]==2)
index2<-which(Xm[s-1,]==2)
ybar1<-ifelse(n1==0,0,mean(glucose[index1]))
ybar2<-ifelse(n2==0,0,mean(glucose[index2]))
vary1<-ifelse(n1<=1,0,var(glucose[index1]))
vary2<-ifelse(n2<=1,0,var(glucose[index2]))
t2n1<-1/(1/t20+n1/phi[4])
mun1<-(mu0/t20+n1*ybar1/phi[4])*t2n1
phi[2]<-rnorm(1,mun1,sqrt(t2n1))
nun1<-nu0+n1
s2n1<-1/nun1*(nu0*s20+(n1-1)*vary1+n1*(ybar1-phi[2])^2)
phi[4]<-1/rgamma(1,nun1/2,nun1*s2n1/2)
t2n2<-1/(1/t20+n2/phi[5])
mun2<-(mu0/t20+n2*ybar2/phi[5])*t2n2
phi[3]<-rnorm(1,mun2,sqrt(t2n2))
nun2<-nu0+n2
s2n2<-1/nun2*(nu0*s20+(n2-1)*vary2+n2*(ybar2-phi[3])^2)
phi[5]<-1/rgamma(1,nun2/2,nun2*s2n2/2)
PHI[s,]<-phi
Xm[s,]<-sample(c(1,2),n,prob=c(phi[1],1-phi[1]),replace=T)
}
thetamax<-apply(PHI[,c(2,3)],1,max)
thetamin<-apply(PHI[,c(2,3)],1,min)
#autocorrelation for theta(1)
acf(thetamin)
#autocorrelation for theta(2)
acf(thetamax)
#effective sample sizes of theta(1)
effectiveSize(thetamin)
#effectice sample sizes of theta(2)
effectiveSize(thetamax)
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
set.seed(2018)
# use relative path for reproducibility
train_dir <- "../data/train/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels = paste("GBM with depth =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
getwdï¼ˆ
getwd()
setwd("/Users/xiaoxi/Documents/GitHub/Spring2019-Proj3-spring2019-proj-grp8/doc")
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
getwd()
source("../lib/superResolutionXG.R")
test_dir <- "../data/train/" # This will be modified for different data sets.
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")
tm_test=NA
if(run.test){
load(file="../output/fit_trainXG.RData")
tm_test <- system.time(performance<-superResolutionXG(train_LR_dir, train_HR_dir,fit_train,index=ts))
}
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
set.seed(2018)
# use relative path for reproducibility
train_dir <- "../data/train/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels = paste("GBM with depth =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
train_label_path
getwd()
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
ts<-c()#index of test set
l<-unique(extra_label$Label)
label<-extra_label$Label
for(i in l){
train_sub<-which(label==i)
ts<-c(ts,sample(train_sub,length(train_sub)/5))
}
train_ind<-setdiff(1:1500,ts)#index of training set
ts
load("../output/feature_train.RData")
feat_train=dat_train$feature
label_train=dat_train$label
source("../lib/trainXGboost.R")
source("../lib/testXGboost.R")
knitr::opts_chunk$set(echo = TRUE)
read.csv(Credit.csv)
source("../lib/trainXGboost.R")
source("../lib/testXGboost.R")
source("../lib/cross_validationXGboost.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.functionXG(feat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cvXGboost.RData")
}
if(run.cv){
load("../output/err_cvXGboost.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.01))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
model_best=model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[,1])]
}
par_best <- list(nr=model_best)
par_best
if(run.cv){
load("../output/err_cvXGboost.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0.003, 0.004))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
if(run.cv){
load("../output/err_cvXGboost.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0.001, 0.004))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
if(run.cv){
load("../output/err_cvXGboost.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0.0025, 0.003))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
if(run.cv){
load("../output/err_cvXGboost.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0.0027, 0.0029))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
err_cv
err_cv[5,1]+err_cv[5,2]
model_labels = paste("GBM with depth =", model_values)
model_values <- array(NA, dim=c(2, 4))
model_values[1, ]<- rep(3, 4)
model_values[2, ]<- c(2,5,10,100)
rownames(model_values)<- c("depth", "nr")
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
model_labels = paste("GBM with depth =", model_values)
model_values <- array(NA, dim=c(2, 4))
model_values[1, ]<- rep(3, 4)
model_values[2, ]<- c(2,5,10,100)
rownames(model_values)<- c("depth", "nr")
source("../lib/trainXGboost.R")
source("../lib/testXGboost.R")
source("../lib/cross_validationXGboost.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.functionXG(feat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cvXGboost.RData")
}
model_values
model_values <- c(2,5,10,100)
model_labels = paste("XGB with nr =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
ts<-c()#index of test set
l<-unique(extra_label$Label)
label<-extra_label$Label
for(i in l){
train_sub<-which(label==i)
ts<-c(ts,sample(train_sub,length(train_sub)/5))
}
train_ind<-setdiff(1:1500,ts)#index of training set
?xgboost
source("../lib/cross_validationXGboost.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.functionXG(feat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cvXGboost.RData")
}
if(run.cv){
load("../output/err_cvXGboost.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0.0027, 0.0029))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
model_best=model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[,1])]
}
par_best <- list(nr=model_best)
par_best
tm_train=NA
tm_train <- system.time(fit_train <- trainXG(feat_train, label_train, par_best))
save(fit_train, file="../output/fit_trainXG.RData")
source("../lib/superResolutionXG.R")
test_dir <- "../data/train/" # This will be modified for different data sets.
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")
tm_test=NA
if(run.test){
load(file="../output/fit_trainXG.RData")
tm_test <- system.time(performance<-superResolutionXG(train_LR_dir, train_HR_dir,fit_train,index=ts))
}
#test mse
performance[1]
#test psnr
performance[2]
